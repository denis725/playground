{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient boosting with mixed estimators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why only use decision trees?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import cycle, islice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, RegressorMixin, clone\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.ensemble._gb_losses import LeastSquaresError\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fake data\n",
    "X, y = make_regression(1000, 50, n_informative=40, random_state=0, noise=1)\n",
    "# or california housing data\n",
    "X, y = fetch_california_housing(return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.89977569e+00, 1.25852527e+01, 2.47411320e+00, 4.73899376e-01,\n",
       "       1.13243469e+03, 1.03857980e+01, 2.13590065e+00, 2.00348319e+00])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.std(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0.4999    ,    1.        ,    0.84615385,    0.33333333,\n",
       "          3.        ,    0.69230769,   32.54      , -124.35      ])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.min(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.50001000e+01,  5.20000000e+01,  1.41909091e+02,  3.40666667e+01,\n",
       "        3.56820000e+04,  1.24333333e+03,  4.19500000e+01, -1.14310000e+02])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.max(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.14999, 5.00001, 2.068558169089147, 1.1539282040412253)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.min(), y.max(), y.mean(), y.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Purposefully no feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## custom code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "no `set_params` on estimators implemented yet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### light weight implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArbitraryBoostingRegressor(BaseEstimator, RegressorMixin):\n",
    "    def __init__(self, estimators, n_estimators=10, learning_rate=0.1):\n",
    "        self.estimators = estimators\n",
    "        self.n_estimators = n_estimators\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "        assert self.estimators\n",
    "        \n",
    "    def _estimator_cycle(self):\n",
    "        for estimator in islice(cycle(self.estimators), self.n_estimators):\n",
    "            yield clone(estimator)\n",
    "            \n",
    "    def fit(self, X, y, **fit_params):\n",
    "        self.loss_ = LeastSquaresError(1)\n",
    "        self.estimators_ = []\n",
    "        self.errors_ = []\n",
    "        y_resid = y\n",
    "\n",
    "        self.init_ = self.loss_.init_estimator()\n",
    "        y_resid = y - self.init_.fit(X, y, **fit_params).predict(X)\n",
    "\n",
    "        for estimator in self._estimator_cycle():\n",
    "            y_pred = estimator.fit(X, y_resid, **fit_params).predict(X)\n",
    "            self.estimators_.append(estimator)\n",
    "            y_resid = y_resid - y_pred * self.learning_rate\n",
    "            self.errors_.append(mean_squared_error(y_resid, y_pred))\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        y_pred = self.init_.predict(X)\n",
    "        for estimator in self.estimators_:\n",
    "            y_pred += self.learning_rate * estimator.predict(X)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### inheriting from GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TreeWrapper:\n",
    "    def __init__(self, obj):\n",
    "        self.obj = obj\n",
    "        \n",
    "    @property\n",
    "    def tree_(self):\n",
    "        return self.obj\n",
    "    \n",
    "    def __getattr__(self, attr):\n",
    "        return getattr(self.obj, attr)\n",
    "\n",
    "\n",
    "class ArbitraryBoostingRegressor2(GradientBoostingRegressor):\n",
    "    def __init__(\n",
    "        self,\n",
    "        estimators,\n",
    "        *,\n",
    "        loss='ls',\n",
    "        learning_rate=0.1,\n",
    "        n_estimators=10,\n",
    "        subsample=1.0,\n",
    "        criterion='friedman_mse',\n",
    "        min_samples_split=2,\n",
    "        min_samples_leaf=1,\n",
    "        min_weight_fraction_leaf=0.0,\n",
    "        max_depth=3,\n",
    "        min_impurity_decrease=0.0,\n",
    "        min_impurity_split=None,\n",
    "        init=None,\n",
    "        random_state=None,\n",
    "        max_features=None,\n",
    "        alpha=0.9,\n",
    "        verbose=0,\n",
    "        max_leaf_nodes=None,\n",
    "        warm_start=False,\n",
    "        presort='deprecated',\n",
    "        validation_fraction=0.1,\n",
    "        n_iter_no_change=None,\n",
    "        tol=0.0001,\n",
    "        ccp_alpha=0.0,\n",
    "    ):\n",
    "        super().__init__(\n",
    "            loss=loss,\n",
    "            learning_rate=learning_rate,\n",
    "            n_estimators=n_estimators,\n",
    "            subsample=subsample,\n",
    "            criterion=criterion,\n",
    "            min_samples_split=min_samples_split,\n",
    "            min_samples_leaf=min_samples_leaf,\n",
    "            min_weight_fraction_leaf=min_weight_fraction_leaf,\n",
    "            max_depth=max_depth,\n",
    "            min_impurity_decrease=min_impurity_decrease,\n",
    "            min_impurity_split=min_impurity_split,\n",
    "            init=init,\n",
    "            random_state=random_state,\n",
    "            max_features=max_features,\n",
    "            alpha=alpha,\n",
    "            verbose=verbose,\n",
    "            max_leaf_nodes=max_leaf_nodes,\n",
    "            warm_start=warm_start,\n",
    "            presort=presort,\n",
    "            validation_fraction=validation_fraction,\n",
    "            n_iter_no_change=n_iter_no_change,\n",
    "            tol=tol,\n",
    "            ccp_alpha=ccp_alpha,\n",
    "        )\n",
    "        self.estimators = estimators\n",
    "\n",
    "    def _fit_stage(\n",
    "        self, i, X, y, raw_predictions, sample_weight, sample_mask,\n",
    "        random_state, X_idx_sorted, X_csc=None, X_csr=None):\n",
    "        \"\"\"Fit another stage of ``n_classes_`` trees to the boosting model. \"\"\"\n",
    "\n",
    "        assert sample_mask.dtype == np.bool\n",
    "        loss = self.loss_\n",
    "        original_y = y\n",
    "\n",
    "        # Need to pass a copy of raw_predictions to negative_gradient()\n",
    "        # because raw_predictions is partially updated at the end of the loop\n",
    "        # in update_terminal_regions(), and gradients need to be evaluated at\n",
    "        # iteration i - 1.\n",
    "        raw_predictions_copy = raw_predictions.copy()\n",
    "\n",
    "        for k in range(loss.K):\n",
    "            if loss.is_multi_class:\n",
    "                y = np.array(original_y == k, dtype=np.float64)\n",
    "\n",
    "            residual = loss.negative_gradient(y, raw_predictions_copy, k=k,\n",
    "                                              sample_weight=sample_weight)\n",
    "\n",
    "            # induce regression tree on residuals\n",
    "            tree = TreeWrapper(clone(next(islice(cycle(self.estimators), i, i+1))))\n",
    "\n",
    "            if self.subsample < 1.0:\n",
    "                # no inplace multiplication!\n",
    "                sample_weight = sample_weight * sample_mask.astype(np.float64)\n",
    "\n",
    "            X = X_csr if X_csr is not None else X\n",
    "            tree.fit(X, residual)  # remaining arguments not supported\n",
    "\n",
    "            # update tree leaves\n",
    "            loss.update_terminal_regions(\n",
    "                tree, X, y, residual, raw_predictions, sample_weight,\n",
    "                sample_mask, learning_rate=self.learning_rate, k=k)\n",
    "\n",
    "            # add tree to ensemble\n",
    "            self.estimators_[i, k] = tree\n",
    "\n",
    "        return raw_predictions\n",
    "\n",
    "    def _raw_predict_init(self, X):\n",
    "        \"\"\"Check input and compute raw predictions of the init estimator.\"\"\"\n",
    "        self._check_initialized()\n",
    "        if X.shape[1] != self.n_features_:\n",
    "            raise ValueError(\"X.shape[1] should be {0:d}, not {1:d}.\".format(\n",
    "                self.n_features_, X.shape[1]))\n",
    "        if self.init_ == 'zero':\n",
    "            raw_predictions = np.zeros(shape=(X.shape[0], self.loss_.K),\n",
    "                                       dtype=np.float64)\n",
    "        else:\n",
    "            raw_predictions = self.loss_.get_init_raw_predictions(\n",
    "                X, self.init_).astype(np.float64)\n",
    "        return raw_predictions\n",
    "\n",
    "    def _raw_predict(self, X):\n",
    "        \"\"\"Return the sum of the trees raw predictions (+ init estimator).\"\"\"\n",
    "        raw_predictions = self._raw_predict_init(X)\n",
    "        for i in range(self.n_estimators):\n",
    "            regr = self.estimators_[i][0]\n",
    "            raw_predictions += self.learning_rate * regr.predict(X).reshape(-1, 1)\n",
    "        return raw_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fit a single model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6263952602050491"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abr = ArbitraryBoostingRegressor([LinearRegression()])\n",
    "abr.fit(X_train, y_train)\n",
    "mean_squared_error(y_valid, abr.predict(X_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5273812806033222,\n",
       " 0.5258319802944061,\n",
       " 0.5245770470441843,\n",
       " 0.5235605511115047,\n",
       " 0.5227371894060342,\n",
       " 0.5220702664246031,\n",
       " 0.5215300588096439,\n",
       " 0.5210924906415269,\n",
       " 0.5207380604253522,\n",
       " 0.5204509719502506]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abr.errors_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### linear + dt + knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6263952602050491"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr = ArbitraryBoostingRegressor([LinearRegression(), DecisionTreeRegressor(), KNeighborsRegressor()])\n",
    "abr.fit(X_train, y_train)\n",
    "mean_squared_error(y_valid, abr.predict(X_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5273812806033222,\n",
       " 0.5258319802944061,\n",
       " 0.5245770470441843,\n",
       " 0.5235605511115047,\n",
       " 0.5227371894060342,\n",
       " 0.5220702664246031,\n",
       " 0.5215300588096439,\n",
       " 0.5210924906415269,\n",
       " 0.5207380604253522,\n",
       " 0.5204509719502506]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abr.errors_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cross validate approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "compare the 2 implementations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6723538160141442\n",
      "[-0.60034349 -0.5952506  -0.69019247 -0.71269834 -0.76328417]\n",
      "CPU times: user 9.03 s, sys: 39 ms, total: 9.06 s\n",
      "Wall time: 8.52 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "regr = ArbitraryBoostingRegressor([DecisionTreeRegressor()])\n",
    "scores = cross_val_score(regr, X, y, cv=5, scoring='neg_mean_squared_error')\n",
    "print(-np.mean(scores))\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6722669141379157\n",
      "[-0.58848153 -0.59639745 -0.70226855 -0.71117485 -0.76301219]\n",
      "CPU times: user 8.53 s, sys: 43.8 ms, total: 8.57 s\n",
      "Wall time: 8.57 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "regr = ArbitraryBoostingRegressor2([DecisionTreeRegressor()])\n",
    "scores = cross_val_score(regr, X, y, cv=5, scoring='neg_mean_squared_error')\n",
    "print(-np.mean(scores))\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "use default GradientBoostingRegressor hyper params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7011773270758519\n",
      "[-0.62248244 -0.63549276 -0.74758768 -0.78483192 -0.71549184]\n",
      "CPU times: user 1.74 s, sys: 40 µs, total: 1.74 s\n",
      "Wall time: 1.74 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dt = DecisionTreeRegressor(\n",
    "    criterion='friedman_mse',\n",
    "    min_samples_split=2,\n",
    "    min_samples_leaf=1,\n",
    "    min_weight_fraction_leaf=0.0,\n",
    "    max_depth=3,\n",
    "    min_impurity_decrease=0.0,\n",
    "    min_impurity_split=None,\n",
    ")\n",
    "regr = ArbitraryBoostingRegressor2([dt])\n",
    "scores = cross_val_score(regr, X, y, cv=5, scoring='neg_mean_squared_error')\n",
    "print(-np.mean(scores))\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6535256771574559\n",
      "[-0.56811679 -0.69759173 -0.75929642 -0.65384625 -0.5887772 ]\n",
      "CPU times: user 595 ms, sys: 20 ms, total: 615 ms\n",
      "Wall time: 157 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "regr = ArbitraryBoostingRegressor([LinearRegression()])\n",
    "scores = cross_val_score(regr, X, y, cv=5, scoring='neg_mean_squared_error')\n",
    "print(-np.mean(scores))\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6535163904654909\n",
      "[-0.5680934  -0.69759844 -0.75928304 -0.65383644 -0.58877063]\n",
      "CPU times: user 536 ms, sys: 7.73 ms, total: 544 ms\n",
      "Wall time: 137 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "regr = ArbitraryBoostingRegressor2([LinearRegression()])\n",
    "scores = cross_val_score(regr, X, y, cv=5, scoring='neg_mean_squared_error')\n",
    "print(-np.mean(scores))\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2037599868343167\n",
      "[-1.09356936 -1.03899702 -1.35285596 -1.18142013 -1.35195747]\n",
      "CPU times: user 6.06 s, sys: 16 ms, total: 6.08 s\n",
      "Wall time: 5.51 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "regr = ArbitraryBoostingRegressor([KNeighborsRegressor()])\n",
    "scores = cross_val_score(regr, X, y, cv=5, scoring='neg_mean_squared_error')\n",
    "print(-np.mean(scores))\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2037599868343167\n",
      "[-1.09356936 -1.03899702 -1.35285596 -1.18142013 -1.35195747]\n",
      "CPU times: user 5.4 s, sys: 32 ms, total: 5.43 s\n",
      "Wall time: 5.43 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "regr = ArbitraryBoostingRegressor2([KNeighborsRegressor()])\n",
    "scores = cross_val_score(regr, X, y, cv=5, scoring='neg_mean_squared_error')\n",
    "print(-np.mean(scores))\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### lr + dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6334502502318948\n",
      "[-0.55735801 -0.63247047 -0.70369275 -0.67487158 -0.59885843]\n",
      "CPU times: user 3.81 s, sys: 67.9 ms, total: 3.88 s\n",
      "Wall time: 973 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "regr = ArbitraryBoostingRegressor([LinearRegression(), dt])\n",
    "scores = cross_val_score(regr, X, y, cv=5, scoring='neg_mean_squared_error')\n",
    "print(-np.mean(scores))\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6334443270638227\n",
      "[-0.55734265 -0.63247685 -0.70368564 -0.67486366 -0.59885283]\n",
      "CPU times: user 3.79 s, sys: 48 ms, total: 3.84 s\n",
      "Wall time: 960 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "regr = ArbitraryBoostingRegressor2([LinearRegression(), dt])\n",
    "scores = cross_val_score(regr, X, y, cv=5, scoring='neg_mean_squared_error')\n",
    "print(-np.mean(scores))\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### lr + dt + knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7240332948253368\n",
      "[-0.6353083  -0.70156824 -0.81329698 -0.74860433 -0.72138863]\n",
      "CPU times: user 9.27 s, sys: 152 ms, total: 9.43 s\n",
      "Wall time: 2.36 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "regr = ArbitraryBoostingRegressor([LinearRegression(), dt, KNeighborsRegressor()])\n",
    "scores = cross_val_score(regr, X, y, cv=5, scoring='neg_mean_squared_error')\n",
    "print(-np.mean(scores))\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7240273214247799\n",
      "[-0.63529467 -0.70157353 -0.81329003 -0.7485971  -0.72138127]\n",
      "CPU times: user 9.85 s, sys: 132 ms, total: 9.98 s\n",
      "Wall time: 2.49 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "regr = ArbitraryBoostingRegressor2([LinearRegression(), dt, KNeighborsRegressor()])\n",
    "scores = cross_val_score(regr, X, y, cv=5, scoring='neg_mean_squared_error')\n",
    "print(-np.mean(scores))\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### benchmarks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3702550894247665\n",
      "[-1.3064619  -1.19893373 -1.57273505 -1.25865506 -1.5144897 ]\n",
      "CPU times: user 42.7 ms, sys: 34 µs, total: 42.8 ms\n",
      "Wall time: 10.9 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "regr = DummyRegressor()\n",
    "scores = cross_val_score(regr, X, y, cv=5, scoring='neg_mean_squared_error')\n",
    "print(-np.mean(scores))\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### vanilla gradient boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7011773270758519\n",
      "[-0.62248244 -0.63549276 -0.74758768 -0.78483192 -0.71549184]\n",
      "CPU times: user 2.26 s, sys: 7.96 ms, total: 2.26 s\n",
      "Wall time: 1.75 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "regr = GradientBoostingRegressor(n_estimators=10)\n",
    "scores = cross_val_score(regr, X, y, cv=5, scoring='neg_mean_squared_error')\n",
    "print(-np.mean(scores))\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4847291292478402\n",
      "[-0.62378846 -0.38590051 -0.41904684 -0.48970468 -0.50520516]\n",
      "CPU times: user 5.16 s, sys: 12 ms, total: 5.17 s\n",
      "Wall time: 5.17 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "regr = RandomForestRegressor(n_estimators=10)\n",
    "scores = cross_val_score(regr, X, y, cv=5, scoring='neg_mean_squared_error')\n",
    "print(-np.mean(scores))\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### bagging + lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5587854379934888\n",
      "[-0.49734083 -0.62139618 -0.63548575 -0.54329421 -0.49641022]\n",
      "CPU times: user 962 ms, sys: 8.06 ms, total: 970 ms\n",
      "Wall time: 249 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "regr = BaggingRegressor(LinearRegression(), n_estimators=10)\n",
    "scores = cross_val_score(regr, X, y, cv=5, scoring='neg_mean_squared_error')\n",
    "print(-np.mean(scores))\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### bagging + dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "should roughly equal rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.46562762669283\n",
      "[-0.51150194 -0.37253359 -0.42157403 -0.51776368 -0.5047649 ]\n",
      "CPU times: user 5.65 s, sys: 56 ms, total: 5.71 s\n",
      "Wall time: 5.13 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "regr = BaggingRegressor(DecisionTreeRegressor(), n_estimators=10)\n",
    "scores = cross_val_score(regr, X, y, cv=5, scoring='neg_mean_squared_error')\n",
    "print(-np.mean(scores))\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further ideas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- use a bandit approach to choose next estimator to fit, e.g. Thompson sampling"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
